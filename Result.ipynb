{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BST8GnGoFTdu",
        "outputId": "4c300f37-a481-4ee4-f8c2-011287cfb17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CPU\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 25.8/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ],
      "metadata": {
        "id": "ATTSJMXxFeZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3PsX12LFi6a",
        "outputId": "4186d0b3-a031-4846-81d1-f9936df198bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import yaml\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import shutil\n",
        "shutil.rmtree(\"runs/detect/\")"
      ],
      "metadata": {
        "id": "eg1PNt_PFnAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import shutil\n",
        "\n",
        "def detect_image(img_path):\n",
        "    model = YOLO(\"/content/drive/MyDrive/rvm_object_detection/runs/detect/train9/weights/best.pt\")\n",
        "    model.predict(img_path, save=True, save_txt=True)\n",
        "    \n",
        "    file_name = \"/content/drive/MyDrive/rvm_object_detection/data.yaml\"\n",
        "    with open(file_name, \"r\") as stream:\n",
        "        names = yaml.safe_load(stream)[\"names\"]\n",
        "    \n",
        "    filename = os.path.basename(img_path)\n",
        "    txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "    lis = open(\"/content/runs/detect/predict/labels/\" + txt_filename, \"r\").readlines()\n",
        "\n",
        "    class_indices = []\n",
        "    for l in lis:\n",
        "      ind = int(l.split()[0])\n",
        "      print(ind, names[ind])\n",
        "      class_indices.append(names[ind])\n",
        "    return class_indices\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "ZgS0V6wNF2oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detect_image(\"/content/drive/MyDrive/rvm_object_detection/obj_detection/test/images/FANTA3.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf8GjnafIAKY",
        "outputId": "c9b1c442-3509-405f-e49c-4204240818c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CPU\n",
            "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "1 label saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 canette\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['canette']"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Check our folder and import the model with best validation accuracy\n",
        "loaded_best_model = keras.models.load_model(\"/content/drive/MyDrive/rvmP2VGG16.h5\")"
      ],
      "metadata": {
        "id": "0XJjqeibFfgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def predict_modele_2(path):\n",
        "          # Load the image\n",
        "          img = Image.open(path)\n",
        "\n",
        "          # Resize the image to the input shape of the model\n",
        "          img = img.resize((768, 340))\n",
        "\n",
        "          # Convert the image to a numpy array\n",
        "          img_array = np.array(img)\n",
        "\n",
        "          # Expand the dimensions of the array to match the input shape of the model\n",
        "          img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "          # Load the model\n",
        "          model = tf.keras.models.load_model(\"/content/drive/MyDrive/rvmP2VGG16.h5\")\n",
        "\n",
        "          # Make a prediction\n",
        "          prediction = model.predict(img_array)\n",
        "          # Load the class names\n",
        "          class_names = [\"defective\",\"non_defective\"]\n",
        "\n",
        "          # Make a prediction\n",
        "          prediction = model.predict(img_array)\n",
        "\n",
        "          # Get the predicted class index\n",
        "          predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "          # Get the name of the predicted class\n",
        "          predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "          # Print the predicted class name\n",
        "          print(predicted_class_name)\n",
        "          return predicted_class_name"
      ],
      "metadata": {
        "id": "ldSiaAqHFfob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_modele_2(\"/content/drive/MyDrive/rvm_object_detection/obj_detection/test/images/aug_153_6831672.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "xX0IcmfgH-18",
        "outputId": "f5adac99-66ef-45ef-d209-518beab01cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9cb4cd9e10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "defective\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'defective'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_detect_et_defective(img_path):\n",
        "  shutil.rmtree(\"runs/detect/\")\n",
        "  if 'bouchon' in detect_image(img_path):\n",
        "    print('a rejeter')\n",
        "  else:\n",
        "    if 'defective' in predict_modele_2(img_path):\n",
        "      print('a rejeter def')\n",
        "    else:\n",
        "      print('a acepter')\n"
      ],
      "metadata": {
        "id": "waHRrAE8J6DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_detect_et_defective(\"/content/drive/MyDrive/rvm_object_detection/obj_detection/test/images/BARGOU_1.5LSBSM4.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFi4aP4zJ6Gc",
        "outputId": "090772a6-2c4f-4ebf-d42f-34be1689bd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CPU\n",
            "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "1 label saved to runs/detect/predict/labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 plastic\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "defective\n",
            "a rejeter def\n"
          ]
        }
      ]
    }
  ]
}